{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Onion Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to load raw 3D data from a file, and re-partition the space according to the distance to the center of the space.\n",
    "Let's first load the needed dependencies for this exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking com.github.JulienPeloton:spark-fits_2.11:0.3.0 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/var/folders/my/lfvl285927q2hzk545f39sy40000gn/T/toree_add_deps1918873437903766661/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /var/folders/my/lfvl285927q2hzk545f39sy40000gn/T/toree_add_deps1918873437903766661/https/repo1.maven.org/maven2/com/github/JulienPeloton/spark-fits_2.11/0.3.0/spark-fits_2.11-0.3.0.jar\n",
      "Marking com.github.haifengl:smile-plot:1.5.1 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/var/folders/my/lfvl285927q2hzk545f39sy40000gn/T/toree_add_deps1918873437903766661/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /var/folders/my/lfvl285927q2hzk545f39sy40000gn/T/toree_add_deps1918873437903766661/https/repo1.maven.org/maven2/com/github/haifengl/smile-plot/1.5.1/smile-plot-1.5.1.jar\n",
      "Marking com.github.haifengl:smile-math:1.5.1 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/var/folders/my/lfvl285927q2hzk545f39sy40000gn/T/toree_add_deps1918873437903766661/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /var/folders/my/lfvl285927q2hzk545f39sy40000gn/T/toree_add_deps1918873437903766661/https/repo1.maven.org/maven2/com/github/haifengl/smile-math/1.5.1/smile-math-1.5.1.jar\n",
      "Marking com.github.haifengl:smile-core:1.5.1 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/var/folders/my/lfvl285927q2hzk545f39sy40000gn/T/toree_add_deps1918873437903766661/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /var/folders/my/lfvl285927q2hzk545f39sy40000gn/T/toree_add_deps1918873437903766661/https/repo1.maven.org/maven2/com/github/haifengl/smile-core/1.5.1/smile-core-1.5.1.jar\n",
      "Marking com.github.haifengl:smile-scala_2.11:1.5.1 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/var/folders/my/lfvl285927q2hzk545f39sy40000gn/T/toree_add_deps1918873437903766661/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /var/folders/my/lfvl285927q2hzk545f39sy40000gn/T/toree_add_deps1918873437903766661/https/repo1.maven.org/maven2/com/github/haifengl/smile-scala_2.11/1.5.1/smile-scala_2.11-1.5.1.jar\n",
      "Marking org.swinglabs:swingx:1.6.1 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/var/folders/my/lfvl285927q2hzk545f39sy40000gn/T/toree_add_deps1918873437903766661/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /var/folders/my/lfvl285927q2hzk545f39sy40000gn/T/toree_add_deps1918873437903766661/https/repo1.maven.org/maven2/org/swinglabs/swingx/1.6.1/swingx-1.6.1.jar\n",
      "Starting download from file:/Users/julien/Documents/workspace/myrepos/spark3D/target/scala-2.11/spark3d_2.11-0.1.0.jar\n",
      "Finished download of spark3d_2.11-0.1.0.jar\n",
      "Starting download from file:/Users/julien/Documents/workspace/myrepos/spark3D/lib/jhealpix.jar\n",
      "Finished download of jhealpix.jar\n"
     ]
    }
   ],
   "source": [
    "// Package to read data from FITS file\n",
    "%AddDeps com.github.JulienPeloton spark-fits_2.11 0.3.0\n",
    "\n",
    "// Smile provides visualisation tools\n",
    "%AddDeps com.github.haifengl smile-plot 1.5.1\n",
    "%AddDeps com.github.haifengl smile-math 1.5.1\n",
    "%AddDeps com.github.haifengl smile-core 1.5.1\n",
    "%AddDeps com.github.haifengl smile-scala_2.11 1.5.1\n",
    "\n",
    "// Contains extensions to the Swing GUI toolkit\n",
    "%AddDeps org.swinglabs swingx 1.6.1\n",
    "\n",
    "// Add the spark3d JAR. To generate it, run `sbt ++2.11.8 package at the root of the package`\n",
    "%AddJar file:/Users/julien/Documents/workspace/myrepos/spark3D/target/scala-2.11/spark3d_2.11-0.1.0.jar\n",
    "\n",
    "// Add healpix JAR\n",
    "%AddJar file:/Users/julien/Documents/workspace/myrepos/spark3D/lib/jhealpix.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From raw data RDD to Point3D RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from the test file provided in the spark3d repo.\n",
    "Our raw data contains points with 3D coordinates (spherical: r, theta, phi). Let's transform it into a Point3D RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import com.spark3d.spatial3DRDD._\n",
    "import org.apache.spark.sql.SparkSession\n",
    "val spark = SparkSession.builder().appName(\"OnionSpace\").getOrCreate()\n",
    "\n",
    "val fn = \"../../src/test/resources/astro_obs.fits\"\n",
    "val hdu = 1\n",
    "val columns = \"Z_COSMO,RA,DEC\"\n",
    "val spherical = true\n",
    "\n",
    "// Load the data\n",
    "val pointRDD = new Point3DRDDFromFITS(spark, fn, hdu, columns, spherical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repartitioning of the space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the pointRDD is partitioned randomly (i.e. Spark made partition regardless to the content of the file).\n",
    "Let's repartition our data based on the distance to the center (Onion Space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import com.spark3d.utils.GridType\n",
    "\n",
    "// As we are in local mode, and the file is very small, the RDD pointRDD has only 1 partition.\n",
    "// For the sake of this example, let's increase the number of partition to 10.\n",
    "val pointRDD_part = pointRDD.spatialPartitioning(GridType.LINEARONIONGRID, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let see how our space is now partitioned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List(2104, 2038, 1985, 1974, 2027, 2026, 1898, 1962, 1974, 2012, 0)\n"
     ]
    }
   ],
   "source": [
    "val partitionsAfter = pointRDD_part.mapPartitions(\n",
    "    iter => Array(iter.size).iterator, true).collect()\n",
    "\n",
    "// This is the number of objects per partition. \n",
    "// Last partition is 0 to include points outside (will change in the next release).\n",
    "println(partitionsAfter.toList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's plot the partitioning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import smile.plot._\n",
    "import java.awt.Color\n",
    "import java.awt.{GridLayout, Dimension}\n",
    "\n",
    "import javax.swing.JFrame\n",
    "import javax.swing.JPanel\n",
    "\n",
    "import com.spark3d.utils.Utils.sphericalToEuclidean\n",
    "import org.apache.spark.rdd.RDD\n",
    "import com.spark3d.geometryObjects._\n",
    "\n",
    "/** \n",
    "  * Define palette of colors \n",
    "  *\n",
    "  * @return (Array[java.awt.Color]) Colors for each partition\n",
    "  */\n",
    "def colors : Array[java.awt.Color] = {\n",
    "    Array(Color.BLACK, Color.RED, Color.GREEN, Color.BLUE,\n",
    "          Color.PINK, Color.YELLOW, Color.DARK_GRAY, Color.ORANGE,\n",
    "          Color.MAGENTA, Color.CYAN)\n",
    "}\n",
    "\n",
    "/** \n",
    "  * format the data for smile.\n",
    "  * The data for ScatterPlot must be Array[Array[Double]] (=Array[point3d])\n",
    "  * We add one more dimension which is the partition.\n",
    "  *\n",
    "  * @param rdd : (RDD[Point3D])\n",
    "  *   RDD whose elements are Point3D instances.\n",
    "  * @return (Array[Array[Array[Double]]]) data as partitions -> points -> point -> coordinate \n",
    "  * \n",
    "  */\n",
    "def format_data_for_smile(rdd: RDD[Point3D]) : Array[Array[Array[Double]]] = {\n",
    "    rdd.map(\n",
    "        x=> sphericalToEuclidean(x).center.getCoordinate.toArray)\n",
    "    .glom.collect().toArray\n",
    "}\n",
    "\n",
    "/** \n",
    "  * Show or save the results.\n",
    "  * \n",
    "  * @param display : (String)\n",
    "  *   Either show or save. If save, extension will be given in the outname.\n",
    "  * @param window : (Window)\n",
    "  *   Object generated by ScatterPlot.plot\n",
    "  * @param outname : (String)\n",
    "  *   If save mode, name (incl. extenstion) for the out file.\n",
    "  * @param title : (String)\n",
    "  *   Title of the window.\n",
    "  *\n",
    "  */\n",
    "def MyScatterPlot(display: String, rdd: RDD[Point3D], \n",
    "                outname: String, title: String) : Unit = {\n",
    "    \n",
    "    // Re-arange the data for plotting\n",
    "    val data = format_data_for_smile(rdd)\n",
    "    \n",
    "    // Plot the results\n",
    "    val window = ScatterPlot.plot(data(0), '.', colors(0))\n",
    "    for (part <- 1 to data.size - 2) {\n",
    "      window.points(data(part), '.', colors(part))\n",
    "    }\n",
    "    display match {\n",
    "      case \"show\" => {\n",
    "        val partFrame = new JFrame(title)\n",
    "        partFrame.setLocationRelativeTo(null)\n",
    "        partFrame.getContentPane().add(window)\n",
    "        partFrame.setVisible(true)\n",
    "        partFrame.setSize(new Dimension(500, 500))\n",
    "      }\n",
    "      case \"save\" => {\n",
    "        val partHeadless = new Headless(window);\n",
    "        partHeadless.pack();\n",
    "        partHeadless.setVisible(true);\n",
    "        partHeadless.setSize(new Dimension(500, 500))\n",
    "        window.save(new java.io.File(outname))\n",
    "      }\n",
    "      case _ => throw new AssertionError(\"\"\"\n",
    "        I do not understand the kind of display you want.\n",
    "        Choose between \"show\" and \"save\".\n",
    "        \"\"\")\n",
    "    }\n",
    "}\n",
    "\n",
    "// Set to \"show\" or \"save\"\n",
    "val display = \"show\"\n",
    "\n",
    "// Display the result\n",
    "// Note: for repartitioning, you should always have n+1 partitions - the last one \n",
    "// having zero objects (outside points). TODO: remove this extra partition.\n",
    "MyScatterPlot(display, pointRDD.rawRDD.repartition(11), \"myOnionFigRaw.png\", \"Raw data\")\n",
    "MyScatterPlot(display, pointRDD_part, \"myOnionFig.png\", \"Partitioned data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Raw partitioning             |  Onion Partitioning\n",
    ":-------------------------:|:-------------------------:\n",
    "![title](myOnionFigRaw.png)  |   ![title](myOnionFig.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Et voil√†!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
